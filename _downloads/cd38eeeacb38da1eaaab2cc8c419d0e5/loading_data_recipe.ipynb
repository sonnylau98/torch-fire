{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wNABQiX9Ztvb"
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFaIQ6iPZtvd"
      },
      "source": [
        "\n",
        "# Loading data in PyTorch\n",
        "PyTorch features extensive neural network building blocks with a simple,\n",
        "intuitive, and stable API. PyTorch includes packages to prepare and load\n",
        "common datasets for your model.\n",
        "\n",
        "## Introduction\n",
        "At the heart of PyTorch data loading utility is the\n",
        "[torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)_\n",
        "class. It represents a Python iterable over a dataset. Libraries in\n",
        "PyTorch offer built-in high-quality datasets for you to use in\n",
        "[torch.utils.data.Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)_.\n",
        "These datasets are currently available in:\n",
        "\n",
        "* [torchvision](https://pytorch.org/vision/stable/datasets.html)_\n",
        "* [torchaudio](https://pytorch.org/audio/stable/datasets.html)_\n",
        "* [torchtext](https://pytorch.org/text/stable/datasets.html)_\n",
        "\n",
        "with more to come.\n",
        "Using the ``yesno`` dataset from ``torchaudio.datasets.YESNO``, we will\n",
        "demonstrate how to effectively and efficiently load data from a PyTorch\n",
        "``Dataset`` into a PyTorch ``DataLoader``.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6FFA7b-Ztvf"
      },
      "source": [
        "## Setup\n",
        "Before we begin, we need to install ``torchaudio`` to have access to the\n",
        "dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XqPsJIEZtvf"
      },
      "outputs": [],
      "source": [
        "# pip install torchaudio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tpjqtjIZtvg"
      },
      "source": [
        "To run in Google Colab, uncomment the following line:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlViRyH7Ztvh"
      },
      "outputs": [],
      "source": [
        "# !pip install torchaudio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tpYdg3EZtvh"
      },
      "source": [
        "## Steps\n",
        "\n",
        "1. Import all necessary libraries for loading our data\n",
        "2. Access the data in the dataset\n",
        "3. Loading the data\n",
        "4. Iterate over the data\n",
        "5. [Optional] Visualize the data\n",
        "\n",
        "\n",
        "## 1. Import necessary libraries for loading our data\n",
        "\n",
        "For this recipe, we will use ``torch`` and ``torchaudio``. Depending on\n",
        "what built-in datasets you use, you can also install and import\n",
        "``torchvision`` or ``torchtext``.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Qibqug6lZtvj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchaudio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRZkpid0Ztvm"
      },
      "source": [
        "## 2. Access the data in the dataset\n",
        "\n",
        "The ``yesno`` dataset in ``torchaudio`` features sixty recordings of one\n",
        "individual saying yes or no in Hebrew; with each recording being eight\n",
        "words long ([read more here](https://www.openslr.org/1/)_).\n",
        "\n",
        "``torchaudio.datasets.YESNO`` creates a dataset for ``yesno``.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ae8HE3ZBZtvn"
      },
      "outputs": [],
      "source": [
        "torchaudio.datasets.YESNO(\n",
        "     root='./',\n",
        "     url='http://www.openslr.org/resources/1/waves_yesno.tar.gz',\n",
        "     folder_in_archive='waves_yesno',\n",
        "     download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBtUOtAcZtvo"
      },
      "source": [
        "Each item in the dataset is a tuple of the form: (waveform, sample_rate,\n",
        "labels).\n",
        "\n",
        "You must set a ``root`` for the ``yesno`` dataset, which is where the\n",
        "training and testing dataset will exist. The other parameters are\n",
        "optional, with their default values shown. Here is some additional\n",
        "useful info on the other parameters:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixXOxKs0Ztvo"
      },
      "outputs": [],
      "source": [
        "# * ``download``: If true, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded, it is not downloaded again.\n",
        "#\n",
        "# Let’s access our ``yesno`` data:\n",
        "#\n",
        "\n",
        "# A data point in ``yesno`` is a tuple (waveform, sample_rate, labels) where labels\n",
        "# is a list of integers with 1 for yes and 0 for no.\n",
        "yesno_data = torchaudio.datasets.YESNO('./', download=True)\n",
        "\n",
        "# Pick data point number 3 to see an example of the the ``yesno_data``:\n",
        "n = 3\n",
        "waveform, sample_rate, labels = yesno_data[n]\n",
        "print(\"Waveform: {}\\nSample rate: {}\\nLabels: {}\".format(waveform, sample_rate, labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCKAP6ObZtvp"
      },
      "source": [
        "When using this data in practice, it is best practice to provision the\n",
        "data into a “training” dataset and a “testing” dataset. This ensures\n",
        "that you have out-of-sample data to test the performance of your model.\n",
        "\n",
        "## 3. Loading the data\n",
        "\n",
        "Now that we have access to the dataset, we must pass it through\n",
        "``torch.utils.data.DataLoader``. The ``DataLoader`` combines the dataset\n",
        "and a sampler, returning an iterable over the dataset.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Z5Pa6SoZtvp"
      },
      "outputs": [],
      "source": [
        "data_loader = torch.utils.data.DataLoader(yesno_data,\n",
        "                                          batch_size=1,\n",
        "                                          shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mX9LkH7wZtvp"
      },
      "source": [
        "## 4. Iterate over the data\n",
        "\n",
        "Our data is now iterable using the ``data_loader``. This will be\n",
        "necessary when we begin training our model! You will notice that now\n",
        "each data entry in the ``data_loader`` object is converted to a tensor\n",
        "containing tensors representing our waveform, sample rate, and labels.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gg1HEpnOZtvq"
      },
      "outputs": [],
      "source": [
        "for data in data_loader:\n",
        "  print(\"Data: \", data)\n",
        "  print(\"Waveform: {}\\nSample rate: {}\\nLabels: {}\".format(data[0], data[1], data[2]))\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ozwJoCGZtvq"
      },
      "source": [
        "## 5. [Optional] Visualize the data\n",
        "\n",
        "You can optionally visualize your data to further understand the output\n",
        "from your ``DataLoader``.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-W7WRlkZtvq"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(data[0][0].numpy())\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(waveform.t().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A13b1w4NZtvq"
      },
      "source": [
        "Congratulations! You have successfully loaded data in PyTorch.\n",
        "\n",
        "## Learn More\n",
        "\n",
        "Take a look at these other recipes to continue your learning:\n",
        "\n",
        "- [Defining a Neural Network](https://pytorch.org/tutorials/recipes/recipes/defining_a_neural_network.html)_\n",
        "- [What is a state_dict in PyTorch](https://pytorch.org/tutorials/recipes/recipes/what_is_state_dict.html)_\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}